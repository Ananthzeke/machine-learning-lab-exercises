{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5 - Classification Algorithms (BBNN & SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Back Propogation Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Program 1 - Implementing BPNN from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AIM\n",
    "To implement Back Propogation Neural Network from scratch in python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ALGORITHM\n",
    "##### Forward propogation\n",
    "###### Single input\n",
    "$$\n",
    "\\newcommand{\\vect}[1]{\\boldsymbol{\\mathbf{#1}}}\n",
    "\\newcommand{\\matrix}[1]{\\begin{bmatrix}{#1}\\end{bmatrix}}\n",
    "\\begin{align*}\n",
    "\\vect{o}_{-1} &= \\vect{x}_i\\\\\n",
    "\\vect{o}_k &= \\vect{\\phi}_k\\left(\n",
    "\\vect{W}_k \n",
    "\\matrix{ 1 \\\\ \\vect{o}_{k-1}}\n",
    "\\right) &\\text{for }k = 0,..,n-1\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Batch input\n",
    "$$\n",
    "\\newcommand{\\vect}[1]{\\boldsymbol{\\mathbf{#1}}}\n",
    "\\begin{align*}\n",
    "\\vect{O}_{-1} &= \\vect{X}^T\\\\\n",
    "\\vect{O}_k &= \\vect{\\phi}_k\\left(\n",
    "\\vect{W}_k^T \n",
    "\\matrix{ \\vect{1} \\\\ \\vect{O}_{k-1}}\n",
    "\\right) &\\text{for }k = 0,..,n-1\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Error\n",
    "###### Single Input\n",
    "$$\n",
    "E = \\frac{1}{2}||\\vect{o}_{n-1}-\\vect{t}||_2\n",
    "$$\n",
    "###### Batch Input\n",
    "$$\n",
    "E = \\sum_i \\frac{1}{2}||\\vect{o}^{(i)}_{n-1}-\\vect{t}||_2\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Backward Propogation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Single input\n",
    "$$\n",
    "\\newcommand{\\diff}[2]{\\frac{\\mathrm{d}{#1}}{\\mathrm{d}{#2}}}\n",
    "\\vect{\\delta}_{k} = \\diff{E}{\\vect{o}_{k}}\\circ \\vect{\\phi}'(\\text{net}_{k} )\\\\\n",
    "\\diff{E}{\\vect{o}_{k}} = \\begin{cases}\n",
    "(\\vect{o}_{n-1}-\\vect{t}) & k=n-1\\\\\n",
    "\\vect{W}^T_{k+1}\\vect{o}_{k+1} & k = n-2,...,-1 \\\\\n",
    "\\end{cases}\\\\\n",
    "\\vect{\\phi}'(\\text{net}_{k}) = \\vect{o}_k \\circ (\\vect{1}-\\vect{o}_k)  \\text{ for }   k = n-1,...,0 \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "###### Batch input\n",
    "$$\n",
    "\\newcommand{\\diff}[2]{\\frac{\\mathrm{d}{#1}}{\\mathrm{d}{#2}}}\n",
    "\\vect{\\Delta}_{k} = \\diff{E}{\\vect{O}_{k}}\\circ \\vect{\\phi}'(\\text{net}_{k} )\\\\\n",
    "\\diff{E}{\\vect{O}_{k}} = \\begin{cases}\n",
    "(\\vect{O}_{n-1}-\\vect{t}) & k=n-1\\\\\n",
    "\\vect{W}_{k+1}^T \\vect{O}_{k+1} & k = n-2,...,-1 \\\\\n",
    "\\end{cases}\\\\\n",
    "\\vect{\\phi}'(\\text{net}_{k}) = \\vect{O}_k \\circ (\\vect{1}-\\vect{O}_k)  \\text{ for }   k = n-1,...,0 \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weight Update\n",
    "###### Single Input\n",
    "$$\n",
    "\\vect{W}_k := \\vect{W}_k - \\alpha \\diff{E}{\\vect{W}_k}\\\\\n",
    "\\diff{E}{\\vect{W}_k} = \\vect{\\delta}_{k}\n",
    "\\matrix{1 \\\\ \\vect{o}_{k-1}}^T\\ \\text{for } k = n-1,...,0 \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Batch Input\n",
    "$$\n",
    "\\vect{W}_k := \\vect{W}_k - \\alpha \\diff{E}{\\vect{W}_k}\\\\\n",
    "\\diff{E}{\\vect{W}_k} = \\vect{\\Delta}_{k}\n",
    "\\matrix{1 \\\\ \\vect{O}_{k-1}}^T \\text{for } k = n-1,...,0 \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where  \n",
    "$\\vect{x}_k$ - the input vector  \n",
    "$\\vect{o}_k$ - the output vector of the $k$th layer  \n",
    "$\\vect{\\delta}_k$ - the delta vector of the $k$th layer  \n",
    "$\\vect{W}_k$ - the weight matrix of the $k$th layer  \n",
    "$\\vect{X}_k$ - the batch input matfix  \n",
    "$\\vect{O}_k$ - the batch output matrix of the $k$th layer  \n",
    "$\\vect{\\Delta}_k$ - the batch delta matrix of the $k$th layer  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1 - Defining class for BPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPNN:\n",
    "    def __init__(\n",
    "        self,hidden_layer_sizes,\n",
    "        l_rate=.001,\n",
    "        n_epoch=20,\n",
    "        batch_size=20,\n",
    "        random_state=0\n",
    "    ):\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.l_rate= l_rate\n",
    "        self.n_epoch = n_epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        self.n = len(hidden_layer_sizes)+1\n",
    "        self.outputs = [None]*(self.n+1)\n",
    "        self.delta = [None]*self.n\n",
    "        \n",
    "        \n",
    "    def activation(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def d_activation(self,x):\n",
    "         return x * (1 - x)\n",
    "    \n",
    "    def pad_ones(X):\n",
    "        pad_width = [(1,0),(0,0)]\n",
    "        return np.pad(X,pad_width=pad_width,constant_values=1)\n",
    "    \n",
    "    def inputs(self,i):\n",
    "        return BPNN.pad_ones(self.outputs[i-1])\n",
    "    \n",
    "    def initialize_random_weights(self):\n",
    "        np.random.seed(self.random_state)\n",
    "        self.weights = [\n",
    "            np.random.random((o,i+1))\n",
    "            for i,o in zip(\n",
    "                [self.n_inputs]+self.hidden_layer_sizes,\n",
    "                self.hidden_layer_sizes+[self.n_outputs]\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    def forward_propagate(self, inputs):\n",
    "        assert (self.weights is not None),\"weights not given\"\n",
    "        self.outputs[-1] = inputs\n",
    "        for i in range(self.n):\n",
    "            self.outputs[i] = self.activation(\n",
    "                self.weights[i] @ self.inputs(i)\n",
    "            )\n",
    "        return self.outputs[self.n-1]\n",
    "    \n",
    "    def backward_propagate_error(self, expected):\n",
    "        for i in range(self.n-1, -1, -1):\n",
    "            if i == self.n-1:\n",
    "                errors = self.outputs[i] - expected\n",
    "            else:\n",
    "                errors = self.weights[i+1][:,1:].T @ self.delta[i+1] \n",
    "            self.delta[i] = errors * self.d_activation(self.outputs[i])\n",
    "\n",
    "    def update_weights(self):\n",
    "        for i in range(self.n):\n",
    "            self.weights[i] -= self.l_rate * self.delta[i] @ self.inputs(i).T\n",
    "        \n",
    "    def error(self,actual,predicted):\n",
    "        error = actual-predicted\n",
    "        return np.sum(error * error)\n",
    "    \n",
    "    def fit(self, X_train,y_train,verbose=False):\n",
    "        m = X_train.shape[0]\n",
    "        input_matrix = X_train.T\n",
    "        classes = np.unique(y_train)\n",
    "        target_matrix = (y_train.reshape(-1,1) == classes).T\n",
    "        self.n_inputs = input_matrix.shape[0]\n",
    "        self.n_outputs = target_matrix.shape[0]\n",
    "        self.initialize_random_weights()\n",
    "        if verbose:\n",
    "            print(\"Initial Weights:\")\n",
    "            print(*self.weights,sep=\"\\n\")\n",
    "            print(\"Training:\")\n",
    "            \n",
    "        for epoch in range(self.n_epoch):\n",
    "            sum_error = 0\n",
    "            fs = range(m+self.batch_size)\n",
    "            for f,t in zip(fs,fs[1:]):\n",
    "                outputs = self.forward_propagate(input_matrix[:,f:t])\n",
    "                sum_error += self.error(target_matrix[:,f:t],outputs)\n",
    "                self.backward_propagate_error(target_matrix[:,f:t])\n",
    "                self.update_weights()\n",
    "            if verbose:\n",
    "                print(f'> epoch={epoch+1}, lrate={self.l_rate:.3}, error={sum_error/m:.5f}')\n",
    "        if verbose:\n",
    "            print(\"Trained Weights:\")\n",
    "            print(*self.weights,sep=\"\\n\")\n",
    "            \n",
    "    def predict(self, inputs):\n",
    "        outputs = self.forward_propagate(inputs.T).T.argmax(axis=-1)\n",
    "        return outputs\n",
    "\n",
    "    def score(self,X_test,y_test):\n",
    "        return (self.predict(X_test)==y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2 - Loading and processing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = pd.read_csv(\"datasets/titanic_processed.csv\")\n",
    "X = titanic_df.drop('Survived',axis = 1).values\n",
    "y = titanic_df['Survived'].values\n",
    "split_ratio = 0.8\n",
    "s = int(split_ratio*X.shape[0])\n",
    "X_train, X_test = X[:s],X[s:]\n",
    "y_train, y_test = y[:s],y[s:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3 - Implementing BPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Weights:\n",
      "[[0.77132064 0.02075195 0.63364823 0.74880388 0.49850701 0.22479665\n",
      "  0.19806286 0.76053071 0.16911084]\n",
      " [0.08833981 0.68535982 0.95339335 0.00394827 0.51219226 0.81262096\n",
      "  0.61252607 0.72175532 0.29187607]\n",
      " [0.91777412 0.71457578 0.54254437 0.14217005 0.37334076 0.67413362\n",
      "  0.44183317 0.43401399 0.61776698]\n",
      " [0.51313824 0.65039718 0.60103895 0.8052232  0.52164715 0.90864888\n",
      "  0.31923609 0.09045935 0.30070006]\n",
      " [0.11398436 0.82868133 0.04689632 0.62628715 0.54758616 0.819287\n",
      "  0.19894754 0.8568503  0.35165264]]\n",
      "[[0.75464769 0.29596171 0.88393648 0.32551164 0.1650159  0.39252924]\n",
      " [0.09346037 0.82110566 0.15115202 0.38411445 0.94426071 0.98762547]\n",
      " [0.45630455 0.82612284 0.25137413 0.59737165 0.90283176 0.53455795]]\n",
      "[[0.59020136 0.03928177 0.35718176 0.07961309]\n",
      " [0.30545992 0.33071931 0.7738303  0.03995921]]\n",
      "Training:\n",
      "> epoch=1, lrate=0.6, error=0.50494\n",
      "> epoch=2, lrate=0.6, error=0.49556\n",
      "> epoch=3, lrate=0.6, error=0.48575\n",
      "> epoch=4, lrate=0.6, error=0.48282\n",
      "> epoch=5, lrate=0.6, error=0.48213\n",
      "> epoch=6, lrate=0.6, error=0.48168\n",
      "> epoch=7, lrate=0.6, error=0.48099\n",
      "> epoch=8, lrate=0.6, error=0.47855\n",
      "> epoch=9, lrate=0.6, error=0.44862\n",
      "> epoch=10, lrate=0.6, error=0.35601\n",
      "> epoch=11, lrate=0.6, error=0.33423\n",
      "> epoch=12, lrate=0.6, error=0.32981\n",
      "> epoch=13, lrate=0.6, error=0.32781\n",
      "> epoch=14, lrate=0.6, error=0.32579\n",
      "> epoch=15, lrate=0.6, error=0.32095\n",
      "> epoch=16, lrate=0.6, error=0.31733\n",
      "> epoch=17, lrate=0.6, error=0.31522\n",
      "> epoch=18, lrate=0.6, error=0.31367\n",
      "> epoch=19, lrate=0.6, error=0.31196\n",
      "> epoch=20, lrate=0.6, error=0.31003\n",
      "Trained Weights:\n",
      "[[ 4.68392235e+00 -1.58322267e+00  6.08278083e-02  1.91321080e+00\n",
      "   3.00223415e+00  8.35644045e-01 -2.36342469e+00  2.10765550e+00\n",
      "  -1.19513306e+00]\n",
      " [-6.43250645e+00  1.11910378e+00  1.13202823e+00  1.02344957e+00\n",
      "   1.11238078e+00 -4.10572796e-01  6.61120231e+00  8.85195243e-01\n",
      "   1.83384743e-01]\n",
      " [-2.36097951e+00  1.11983201e+00  9.55627254e-04  8.04925082e-02\n",
      "   5.58777364e-01 -8.12603863e-02  6.87767940e-01  6.89954075e-02\n",
      "   1.73976875e-01]\n",
      " [ 5.56443733e-01  3.91023803e-01  4.72900547e-01  1.00845741e+00\n",
      "   6.30870808e-01  9.40193153e-01  2.05378673e-01  3.35577560e-02\n",
      "   7.56253826e-02]\n",
      " [-2.96154241e+00  1.67245265e+00 -4.97562913e-01  2.74910676e-01\n",
      "   5.48190808e-01  7.68626678e-02  2.88940510e-01  7.41936662e-01\n",
      "  -5.91390772e-01]]\n",
      "[[ 0.0205264   0.28197314 -0.60738488 -0.83393303 -0.73238479 -0.90720354]\n",
      " [ 1.55143312  3.24739312 -4.83762446 -0.95803066  0.98064778 -0.93586583]\n",
      " [ 0.81131525  2.44061779 -3.07837699 -1.54092428 -0.04542771 -2.73840761]]\n",
      "[[ 1.9115725  -0.88916113 -2.13636354 -2.71497034]\n",
      " [-1.89486834  0.69011496  2.27479065  2.42300961]]\n",
      "Evaluation:\n",
      "Acuracy of the classifier:  0.8258426966292135\n"
     ]
    }
   ],
   "source": [
    "b = BPNN(\n",
    "    hidden_layer_sizes = [5,3],\n",
    "    l_rate=.6, n_epoch=20, batch_size=25,random_state=10\n",
    ")\n",
    "b.fit(X_train,y_train,verbose=True)\n",
    "print(\"Evaluation:\")\n",
    "print(\"Acuracy of the classifier: \",b.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program 1 - Implementing SVM from scratch using CVXOPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AIM\n",
    "To implement SVM from scratch using CVXOPT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formula\n",
    "##### SVM statement in dual form\n",
    "$$\n",
    "\\newcommand{\\vect}[1]{\\boldsymbol{\\mathbf{#1}}}\n",
    "\\begin{aligned}\n",
    "    & \\min_{\\vect{\\alpha}}  \\frac{1}{2}  \\vect{\\alpha}^T  \\left( \\vect{y}\\vect{y}^T \\circ (\\Phi(\\vect{X})\\Phi(\\vect{X})^T \\right)  \\vect{\\alpha} - \\vect{1}^T \\vect{\\alpha}\\\\\n",
    "s.t.&  - \\alpha_i \\leq 0 \\\\\n",
    "    & \\alpha_i \\leq C\\\\\n",
    "    & y^T \\vect{\\alpha} = 0  \n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Standard form of a quadratic program\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    & \\min_{\\vect{x}}  \\frac{1}{2}  \\vect{x}^T  \\vect{P}  \\vect{x} - \\vect{q}^T\\vect{x}\\\\\n",
    "s.t.&  \\vect{G}\\vect{x} \\leq \\vect{h} \\\\\n",
    "    & A \\vect{x} = \\vect{b} \n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Formulization\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\vect{P}&= \\vect{y}\\vect{y}^T \\circ \\Phi(\\vect{X})\\Phi(\\vect{X})^T\n",
    "& \\vect{q}&= - \\vect{1}_n\\\\\n",
    "\\vect{G}&= \\begin{bmatrix}\n",
    "    \\vect{-I}_n\\\\\n",
    "    \\vect{I}_n\n",
    "\\end{bmatrix} \n",
    "& \\vect{h}&=\\begin{bmatrix}\n",
    "    C \\cdot \\vect{1}_n^T\\\\\n",
    "    \\vect{0}_n^T\n",
    "\\end{bmatrix}\\\\\n",
    "\\vect{A} &= [\\vect{y}] \n",
    "&\\vect{b} &= [0]\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Rule\n",
    "$$\n",
    "\\vect{\\hat y} = \\mathrm{sign}\\left( (\\vect{\\alpha}^T \\circ \\vect{y}^T) \\Phi(\\vect{X})\\Phi(\\vect{X})^T  + b \\right) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1 - Defining class for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from cvxopt import solvers\n",
    "from cvxopt import matrix\n",
    "\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self,C,kernel):\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "\n",
    "    def fit(self,X_train,y_train):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.X = self.scaler.fit_transform(X_train)\n",
    "        self.y = y_train.reshape(-1,1)\n",
    "        \n",
    "        n=self.X.shape[0]\n",
    "        I_n = np.eye(n)\n",
    "        P=(self.y@self.y.T)*self.kernel(self.X,self.X)\n",
    "        q=np.full(n,-1)\n",
    "        G=np.vstack((I_n,-1*I_n))\n",
    "        h=np.hstack((np.full(n,self.C),np.zeros(n)))\n",
    "        A=y_train.reshape(1,-1)\n",
    "        b=np.zeros(1)\n",
    "\n",
    "        P,q,G,h,A,b = map(lambda x : matrix(x,tc=\"d\"),(P,q,G,h,A,b))\n",
    "\n",
    "        solution = solvers.qp(P, q, G, h, A, b)\n",
    "        self.a = np.asarray(solution['x']).squeeze()\n",
    "        \n",
    "        support_indices = np.logical_and(self.a>=1e-10, self.a<self.C)\n",
    "        X_S = self.X[support_indices]\n",
    "        self.b = np.mean(self.y - self.a*self.y.T @ self.kernel(self.X, X_S))\n",
    "\n",
    "    def predict(self,X_test):\n",
    "        X_test=self.scaler.transform(X_test)\n",
    "        return np.sign(self.a*self.y.T @ self.kernel(self.X, X_test) + self.b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2 - Defining Radial Basis Function(RBF) Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_kernel(X1,X2,sigma):\n",
    "    return np.exp(-cdist(X1, X2, 'sqeuclidean') / (2*sigma**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3 - Loading and Processing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = pd.read_csv('datasets/titanic_processed.csv')\n",
    "X = titanic_df.drop('Survived',axis = 1).values\n",
    "y = titanic_df['Survived'].values\n",
    "y[y==0] = -1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 4 - Implementing SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.0672e+02 -6.0489e+02  6e+03  8e+00  1e-15\n",
      " 1: -1.0821e+02 -5.1411e+02  6e+02  3e-01  1e-15\n",
      " 2: -1.0989e+02 -1.6099e+02  5e+01  9e-03  2e-15\n",
      " 3: -1.2250e+02 -1.3135e+02  9e+00  1e-03  1e-15\n",
      " 4: -1.2441e+02 -1.2830e+02  4e+00  4e-04  1e-15\n",
      " 5: -1.2525e+02 -1.2680e+02  2e+00  1e-04  1e-15\n",
      " 6: -1.2558e+02 -1.2625e+02  7e-01  7e-06  1e-15\n",
      " 7: -1.2572e+02 -1.2596e+02  2e-01  9e-07  1e-15\n",
      " 8: -1.2577e+02 -1.2588e+02  1e-01  4e-07  1e-15\n",
      " 9: -1.2578e+02 -1.2586e+02  8e-02  2e-07  9e-16\n",
      "10: -1.2580e+02 -1.2582e+02  2e-02  2e-08  1e-15\n",
      "11: -1.2581e+02 -1.2581e+02  6e-03  6e-09  1e-15\n",
      "12: -1.2581e+02 -1.2581e+02  3e-03  1e-09  1e-15\n",
      "13: -1.2581e+02 -1.2581e+02  9e-04  3e-10  9e-16\n",
      "14: -1.2581e+02 -1.2581e+02  3e-04  9e-11  1e-15\n",
      "15: -1.2581e+02 -1.2581e+02  2e-05  4e-15  1e-15\n",
      "Optimal solution found.\n",
      "Accuracy of the classifer: 73.03%\n"
     ]
    }
   ],
   "source": [
    "from functools import partial \n",
    "C = .35\n",
    "sigma = .5\n",
    "kernel = partial(rbf_kernel,sigma=sigma)\n",
    "\n",
    "svm_classifier = SVM(C,kernel)\n",
    "svm_classifier.fit(X_train,y_train)\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "print(f'Accuracy of the classifer: {(y_test == y_pred).mean()*100:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7023248c40563a766f3ae9a0fc81476c1e46277ee22e162240a9cb41b674a272"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
